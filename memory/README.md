# Оптимізація роботи із пам'яттю

## Початковий вхідний файл та його аналіз
```rust
use std::time::Instant;

fn main() {
    let mut matrix = vec![vec![0; 100]; 100];
    let _res = 0;

    let start_time = Instant::now();
    for i in 0..100 {
        for j in 0..100 {
            matrix[j][i] += 1;
        }
    }
    println!("Duration in nanoseconds: {:?}", start_time.elapsed().as_nanos());
}
```

В загальному код не складний. Ми створюємо матрицю розміром 100х100 заповнену нулями. Потім через два вкладені цикли збільшуємо значення кожного елемента матриці на одиницю.

На перший погляд в даному випадку не має що оптимізовувати. Найпростіший і найоптимальніший спосіб пройтися по елементах матриці, то це два цикли. Це так, але насправді є різниця в яким способом ми будемо проходити по матриці.

## Оптимізований код та його аналіз

Розглянемо таку властивіть, як локальність даних. Коли ми звератємося до різних даних, то бажано, щоб вони знаходилися поруч в пам'яті.

У прикладі наведеному вище ми обходимо матрицю по стовпцях, а це є поганою практикою, оскільки в реальності дані матриці зберігаються по рядкх. Тобто ми спочатку зверталися до першого елемента кожного стовпця, потім до кожного другого, і тд. Давайте трохи оптимізуємо це:

```rust
use std::time::Instant;

fn main() {
    let mut matrix = vec![vec![0; 100]; 100];
    let _res = 0;

    let start_time = Instant::now();
    for i in 0..100 {
        for j in 0..100 {
            // matrix[j][i] += 1;
            matrix[i][j] += 1;
        }
    }
    println!("Duration in nanoseconds: {:?}", start_time.elapsed().as_nanos());
}
```

Тепер ми спочатку звертаємося по черзі до всіх елементів першого рядка, потім до всіх елементів другого рядка, потім до третього і тд...

Чи дало це нам насправді якийсь виграш?

## Часові заміри обох прикладів

Для порвніння часу роботи, я запустив кожен із варіантів по 100 разів і порахував середнє арифметичне кожного із них (це звичайно рахувалося автоматично, а не руками :smile: ).

Результат першого (неоптимізованого): `5321624` наносекунд.

Результат другого (оптимізованого): `1973792` наносекунд.

Як бачимо ми маємо виграш у часі. На перший погляд, це небагато, але у великих програмах, які працюються із великою кількістю великих даних, це може значно скоротити час виконання.
